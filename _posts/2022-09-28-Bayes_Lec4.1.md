---
layout: post
title: "Bayes-Lec4.1 贝叶斯统计决策的基本概念"
subtitle: "Basic of Bayes Decision Theory"
author: "Watthu"
header-style: text
mathjax: true
tags:
  - 贝叶斯分析
---

## 统计决策理论的三要素

- **样本空间和样本分布族**

    取值于样本空间 $\mathscr{X}$ 的随机变量 $X$ 及其分布族 $\mathcal{F}=\{F_\theta(x),\theta\in\Theta\}$ 是构成统计决策问题的第一个要素，其中 $F_\theta(x)$ 是 $X$ 的分布函数，$\theta$ 为未知参数，$\Theta$ 为参数空间，$\pmb X=(X_1,\dots,X_n)$ 是总体 $X$ 的简单随机样本。
    
- **行动空间和行为决策规则类**

    决策者对某个统计决策问题可能采取的行动所构成的非空集合，被称为行动空间，记为 $\mathscr{A}$。
    
    - 在估计问题中，常取 $\mathscr{A}=\Theta$，则 $\mathscr{A}$ 就是一切估计量的集合。
    - 在（非随机决策的）检验问题中，$\mathscr{A}$ 只由两个行动组成, 即 $\mathscr{A}=\left\{a_0,a_1\right\}$，其中 $a_0$ 表示接受假设 $H_0$，$a_1$ 表示拒绝假设 $H_0$。

- **损失函数**

    损失函数是定义在 $\Theta\times\mathscr{A}$ 上的非负（可测）函数，记为 $L(\theta,a)$。它表示参数为 $\theta$ 时采取行动 $a\in\mathscr{A}$ 所蒙受的损失。显然，损失越小，决策函数越好。损失函数的类型很多，常用的有平方损失 $L(\theta,a)=(\theta-a)^2$、绝对值损失 $L(\theta,a)=\vert\theta-a\vert$ 和线性损失
    <center>
    $L(\theta,a)=\left\{\begin{array}{ll}
    k_1(\theta-a), & \theta\geq a,\\
    k_2(a-\theta), & \theta<a.
    \end{array}\right.$
    </center>
    
    事实上，绝对值损失是线性损失的一种特殊情况（$k_1=k_2=1$）。

## 风险函数和一致最优决策函数

定义于样本空间 $\mathscr{X}$ 而取值于行动空间 $\mathscr{A}$ 的函数 $\delta=\delta(\pmb x)$ 称为决策函数或判决函数。

设 $\delta$ 是采取的决策行动，若参数为 $\theta$，则由此造成的损失是 $L(\theta,\delta)$，这个量与样本 $\pmb X$ 有关，因而是随机的，故采取行动 $\delta(\pmb X)$ 的效果用平均损失去度量是合理的。这就引入如下风险函数的概念。

---
**定义(风险函数)** 设 $\delta(\pmb x)$ 是 $\theta$ 的一个决策函数，$L(\theta,\delta(\pmb x))$ 是损失函数, 称平均损失
<center>
$\begin{array}{rl}
R(\theta,\delta)=&\!\!\!\!\displaystyle\mathbb E\big[L(\theta,\delta(\pmb X))\big]=\int_{\mathscr{X}}L(\theta,\delta(\pmb x)){\rm d}F(\pmb x\mid\theta)\\
=&\!\!\!\!\displaystyle\left\{\begin{array}{ll}
	\sum\limits_{\pmb x\in \mathscr{X}}L(\theta,\delta(\pmb x))f(\pmb x\mid \theta), & \text{当}~X~\text{为离散型随机变量},\\
	\int_\mathscr{X} L(\theta,\delta(\pmb x))f(\pmb x\mid\theta){\rm d}\pmb x, & \text{当}~X~\text{为连续型随机变量}
	\end{array}\right.
\end{array}$
</center>

为 $\delta(\pmb x)$ 的风险函数，这里 $F(\pmb x\mid\theta)$ 是给定 $\theta$ 时 $\pmb X$ 的分布函数.

---

由于风险函数越小越好，因此在有了风险函数后，我们便可以比较不同决策函数之间的优劣。

---
**定义(一致最优决策函数)** 设 $\delta_1(\pmb x)$ 和 $\delta_2(\pmb x)$ 为 $\theta$ 的两个不同的决策函数，若
<center>
$R(\theta,\delta_1)\leq R(\theta,\delta_2),\quad\forall\theta\in\Theta,$
</center>

且至少存在一个 $\theta_0\in\Theta$ 使严格不等号成立，则称 $\delta_1(\pmb x)$ 优于 $\delta_2(\pmb x)$。

若存在 $\delta^\star=\delta^\star(\pmb x)$，使得对 $\theta$ 的任意一个决策函数 $\delta(\pmb x)$，都有
<center>
$R(\theta,\delta^\star)\leq R(\theta,\delta),\quad\forall\theta\in\Theta,$
</center>

则称 $\delta^\star(\pmb x)$ 为一致最优解或一致最优决策函数。

---

对决策函数 $\delta(\pmb x)$，若不存在一致优于它的决策函数，则称 $\delta(\pmb x)$ 为**可容许**的决策函数。但由于要求一致最优性，这样的可容许的决策一般不存在，人们更多采用Minimax决策或贝叶斯决策。

## 贝叶斯风险和贝叶斯解

在贝叶斯框架下，由于参数 $\theta$ 有先验分布，因此我们希望平均意义下决策函数的贝叶斯风险也是最小的。

---
**定义(贝叶斯风险)** 设 $\delta(\pmb x)$ 是 $\theta$ 的一个决策函数，$R(\theta,\delta)$ 风险函数，$\pi(\theta)$ 为 $\theta$ 的先验分布（$F^\pi(\theta)$ 为分布函数），则称
<center>
$\begin{array}{rl}
R_\pi(\delta(\pmb x))=&\!\!\!\!\displaystyle\int_{\Theta}R(\theta,\delta(\pmb x)){\rm d}F^\pi(\theta)=\mathbb E_\theta\big[R(\theta,\delta(\pmb x))\big]\\
=&\!\!\!\!\left\{\begin{array}{ll}
	\sum\limits_{i}R(\theta_i,\delta)\pi(\theta_i), & \text{当}~\theta~\text{为离散型随机变量},\\
	\int_{\Theta}R(\theta,\delta)\pi(\theta){\rm d}\theta, & \text{当}~\theta~\text{为连续型随机变量}
	\end{array}\right.\\
=&\!\!\!\!\displaystyle\int_{\Theta}\int_{\mathscr{X}}L(\theta,\delta(\pmb x)){\rm d}F(\pmb x\mid\theta){\rm d}F^\pi(\theta)
\end{array}$
</center>

是决策函数 $\delta(\pmb x)$ 的贝叶斯风险，它是将风险函数对 $\theta$ 的先验分布再次求均值的结果。

---

基于贝叶斯风险最小原则，我们就有贝叶斯解的概念。

---
**定义(贝叶斯解)** 设 $\delta_1(\pmb x)$ 和 $\delta_2(\pmb x)$ 为 $\theta$ 的两个不同的决策函数，$\pi(\theta)$ 为 $\theta$ 的先验分布，若
<center>
$R_\pi(\delta_1(\pmb x))\leq R_\pi(\delta_2(\pmb x)),$
</center>

则称 $\delta_1(\pmb x)$ 在贝叶斯风险下优于 $\delta_2(\pmb x)$。

若存在 $\delta^\star(\pmb x)$，使得对 $\theta$ 的任意一个决策函数 $\delta(\pmb x)$，都有
<center>
$R_\pi(\delta^\star(\pmb x))\leq R_\pi(\delta(\pmb x)),$
</center>

则称 $\delta^\star(\pmb x)$ 为所考虑的统计判决问题的贝叶斯解。

---

进一步，考虑基于 $\theta$ 的后验分布的贝叶斯风险（即贝叶斯后验风险）。

---
**定义(贝叶斯后验风险)** 设 $\delta(\pmb x)$ 是 $\theta$ 的一个决策函数，$L(\theta,\delta(\pmb x)$ 是损失函数，$\pi(\theta\mid x)$ 为 $\theta$ 的后验分布，称平均损失
<center>
$\begin{array}{rl}
R(\delta(\pmb x)\mid\pmb x) =&\!\!\!\!\mathbb E_{\theta\vert\pmb x}\big[L(\theta,\delta(\pmb x))\big]\\
=&\!\!\!\!\left\{\begin{array}{ll}
\sum\limits_{i}L(\theta_i,\delta(\pmb x))\pi(\theta_i\mid\pmb x), & \text{当}~\theta~\text{为离散型随机变量},\\
\int_{\Theta}L(\theta,\delta(\pmb x))\pi(\theta\mid\pmb x){\rm d}\theta, & \text{当}~\theta~\text{为连续型随机变量}
\end{array}\right.
\end{array}$
</center>

为决策函数 $\delta(\pmb x)$ 的贝叶斯后验风险。

---

若存在决策函数 $\delta^\star(\pmb x)$ 使得
<center>
$R(\delta^\star(\pmb x)\mid\pmb x)=\min\limits_\delta R(\delta(\pmb x)\mid\pmb x),\quad\forall\delta(\pmb x),$
</center>

则称 $\delta^\star(\pmb x)$ 为后验风险最小准则下的最优贝叶斯决策函数。

### 贝叶斯后验风险与贝叶斯风险的关系

根据二者的定义，我们有
<center>
$\begin{array}{rl}
R_\pi(\delta(\pmb x))=&\!\!\!\!\mathbb E_\theta\big[R(\theta,\delta(\pmb x))\big]=\int_\Theta R(\theta,\delta(\pmb x))\pi(\theta){\rm d}\theta\\
=&\!\!\!\!\displaystyle\int_\Theta\left[\int_{\mathscr{X}}L(\theta,\delta(\pmb x))f(\pmb x\mid\theta){\rm d}\pmb x\right]\pi(\theta){\rm d}\theta\\
=&\!\!\!\!\displaystyle\int_{\mathscr{X}}\left[\int_\Theta L(\theta,\delta(\pmb x))\pi(\theta\mid\pmb x){\rm d}\theta\right]m(\pmb x){\rm d}\pmb x\\
=&\!\!\!\!\displaystyle\int_{\mathscr{X}}R(\delta(\pmb x)\mid\pmb x)m(\pmb x){\rm d}\pmb x=\mathbb E_{\pmb X}\big[R(\delta(\pmb x)\mid\pmb x)\big].
\end{array}$
</center>

这也就是说，贝叶斯风险可以将风险函数按 $\theta$ 的先验分布 $\pi(\theta)$ 求期望，也可以将贝叶斯后验风险按 $\pmb X$ 的边缘分布 $m(\pmb x)$ 求期望。

---
**定理.** 对任何样本 $\pmb x$，若存在非随机化决策函数 $\delta_\pi(\pmb x)$ 满足
<center>
$R(\delta_\pi(\pmb x)\mid\pmb x)=\min\limits_{\delta}R(\delta(\pmb x)\mid\pmb x)$
</center>

则 $\delta_\pi(\pmb x)$ 为先验分布 $\pi(\theta)$ 之下的贝叶斯解。

**证明.** 设 $\delta(\pmb x)$ 为任一非随机化决策函数。由已知条件，可知
<center>
$\displaystyle R(\delta(\pmb x)\mid\pmb x)=\int_\Theta L(\theta,\delta(\pmb x))\pi(\theta\mid\pmb x){\rm d}\theta\geq\int_\Theta L(\theta,\delta_\pi(\pmb x))\pi(\theta\mid\pmb x){\rm d}\theta=R(\delta_\pi(\pmb x)\mid\pmb x)$
</center>

对一切 $\pmb x\in\mathscr{X}$ 成立，将上式两边对 $\pmb X$ 的边缘分布求期望，可得
<center>
$\displaystyle R_\pi(\delta(\pmb x))=\int_{\mathscr{X}}R(\delta(\pmb x)\mid\pmb x)m(\pmb x){\rm d}\pmb x\geq\int_{\mathscr{X}}R(\delta_\pi(\pmb x)\mid\pmb x)m(\pmb x){\rm d}\pmb x=R_\pi(\delta_\pi(\pmb x)).$
</center>

因此，使贝叶斯后验风险达到最小的决策函数 $\delta_\pi(\pmb x)$ 是贝叶斯解。

---

**注.** 若 $\pi(\theta)$ 为广义先验分布，且 $\delta_\pi(\pmb x)$ 是最小化后验贝叶斯风险的最优决策函数，则称 $\delta_\pi(\pmb x)$ 为广义贝叶斯解。上述定理结果仍然正确。

![](/img/in_post/Bayes/BayesLec4_1_1.png)

![](/img/in_post/Bayes/BayesLec4_1_2.png)

## 后记

本文内容参考自中国科学技术大学《贝叶斯分析》（2022Fall）课件。

如对本文内容有任何疑问，请联系 <watthu@mail.ustc.edu.cn>。