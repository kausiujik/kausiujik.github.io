---
layout: post
title: "Bayes-Lec4.2 一般损失函数下的贝叶斯解"
subtitle: "Bayes Solution Under Different Loss Function"
author: "Watthu"
header-style: text
mathjax: true
tags:
  - 贝叶斯分析
---

设 $X\sim f(x\mid\theta)$，$\pi(\theta)$ 为先验密度，$\pmb X=(X_1,\dots,X_n)$ 为总体 $X$ 中抽取的i.i.d.样本，则 $\theta$ 的后验密度为
<center>
$\pi(\theta\mid\pmb x)=\dfrac{f(\pmb x\mid\theta)\pi(\theta)}{\int_\Theta f(\pmb x\mid\theta)\pi(\theta){\rm d}\theta}.$
</center>

设损失函数为 $L(\theta,a)$，常见损失函数有平方损失、加权平方损失、绝对损失、线性损失和0-1损失。下面分别讨论在这几种损失函数下的贝叶斯估计。

## 平方损失下的贝叶斯估计

在平方损失 $L(\theta,a)=(\theta-a)^2$ 下，$\theta$ 的贝叶斯估计为后验期望值，即
<center>
$\hat{\theta}_B(\pmb x)=\mathbb E(\theta\mid\pmb x).$
</center>

**证明.** 设 $\pi(\theta\mid\pmb x)$ 为 $\theta$ 的后验密度，则决策函数 $a$ 的后验风险为
<center>
$\displaystyle R(a\mid\pmb x)=\mathbb E_{\theta\vert\pmb x}[(\theta-a)^2]=\int_\Theta(\theta-a)^2\pi(\theta\mid\pmb x){\rm d}\theta.$
</center>

由
<center>
$\displaystyle\dfrac{{\rm d}R(a\mid\pmb x)}{{\rm d}a}=-2\int_\Theta\theta\pi(\theta\mid\pmb x){\rm d}\theta+2a=0$ 及 $\dfrac{{\rm d}^2R(a\mid\pmb x)}{{\rm d}a^2}=2>0,$
</center>

可知当决策函数 $a$ 为 $\theta$ 的后验分布的均值时，后验风险达到最小，因此平方损失下 $\theta$ 的贝叶斯估计为
<center>
$\displaystyle a=\int_\Theta\theta\pi(\theta\mid\pmb x){\rm d}\theta=\mathbb E(\theta\mid\pmb x)=\hat{\theta}_B(\pmb x).$
</center>

![](/img/in_post/Bayes/BayesLec4_2_1.png)

![](/img/in_post/Bayes/BayesLec4_2_2.png)

![](/img/in_post/Bayes/BayesLec4_2_3.png)

## 加权平方损失下的贝叶斯估计

在加权平方损失 $L(\theta,a)=w(\theta)(\theta-a)^2$ 下，$\theta$ 的贝叶斯估计为
<center>
$\hat{\theta}_B(\pmb x)=\dfrac{\mathbb E(\theta w(\theta)\mid\pmb x)}{\mathbb E(w(\theta)\mid\pmb x)},$
</center>

其中 $w(\theta)$ 为参数空间上的正值函数。

**证明.** 设 $\pi(\theta\mid\pmb x)$ 为 $\theta$ 的后验密度，则决策函数 $a$ 的后验风险为
<center>
$\displaystyle R(a\mid\pmb x)=\mathbb E_{\theta\vert\pmb x}[w(\theta)(\theta-a)^2]=\int_\Theta w(\theta)(\theta-a)^2\pi(\theta\mid\pmb x){\rm d}\theta.$
</center>

由
<center>
$\displaystyle\dfrac{{\rm d}R(a\mid\pmb x)}{{\rm d}a}=-2\int_\Theta\theta w(\theta)\pi(\theta\mid\pmb x){\rm d}\theta+2a\int_\Theta w(\theta)\pi(\theta\mid\pmb x){\rm d}\theta=0,$

$\displaystyle\dfrac{{\rm d}^2R(a\mid\pmb x)}{{\rm d}a^2}=2\int_\Theta w(\theta)\pi(\theta\mid\pmb x){\rm d}\theta>0,$
</center>

可知当决策函数 $a$ 为 $\theta$ 的后验分布的加权均值时，后验风险达到最小，因此加权平方损失下 $\theta$ 的贝叶斯估计为
<center>
$\displaystyle a=\dfrac{\int_\Theta\theta w(\theta)\pi(\theta\mid\pmb x){\rm d}\theta}{\int_\Theta w(\theta)\pi(\theta\mid\pmb x){\rm d}\theta}=\dfrac{\mathbb E(\theta w(\theta)\mid\pmb x)}{\mathbb E(w(\theta)\mid\pmb x)}=\hat{\theta}_B(\pmb x).$
</center>

事实上，加权平方损失就是对平方损失的一般化。

![](/img/in_post/Bayes/BayesLec4_2_4.png)

![](/img/in_post/Bayes/BayesLec4_2_5.png)

## 绝对值损失下的贝叶斯估计

在绝对损失 $L(\theta,a)=|\theta-a|$ 下，$\theta$ 的贝叶斯估计为后验中位数，即
<center>
$\hat{\theta}_B(\pmb x)=\pi_{0.5}(\theta\mid\pmb x)$ $\bigg($ 即满足 $\displaystyle\int_{-\infty}^{\hat{\theta}_B(\pmb x)}\pi(\theta\mid\pmb x){\rm d}\theta=\dfrac{1}{2}\bigg).$
</center>

**证明.** 设 $\pi(\theta\mid\pmb x)$ 为 $\theta$ 的后验密度，则决策函数 $a$ 的后验风险为
<center>
$\begin{array}{rl}
R(a\mid\pmb x)=&\!\!\!\!\displaystyle\mathbb E_{\theta\vert\pmb x}[\vert\theta-a\vert]=\int_{-\infty}^{+\infty}|\theta-a|\pi(\theta\mid\pmb x){\rm d}\theta\\
=&\!\!\!\!\displaystyle\int_{-\infty}^a(a-\theta)\pi(\theta\mid\pmb x){\rm d}\theta+\int_a^{+\infty}(\theta-a)\pi(\theta\mid\pmb x){\rm d}\theta\\
=&\!\!\!\!\displaystyle 2\int_{-\infty}^a(a-\theta)\pi(\theta\mid\pmb x){\rm d}\theta+\int_{-\infty}^{+\infty}(\theta-a)\pi(\theta\mid\pmb x){\rm d}\theta\\
=&\!\!\!\!\displaystyle 2\int_{-\infty}^a(a-\theta)\pi(\theta\mid\pmb x){\rm d}\theta+\mathbb E(\theta\mid\pmb x)-a.
\end{array}$
</center>

由
<center>
$\displaystyle\dfrac{{\rm d}R(a\mid\pmb x)}{{\rm d}a}=2\int_{-\infty}^a\pi(\theta\mid\pmb x){\rm d}\theta-1=0$ 及 $\dfrac{{\rm d}^2R(a\mid\pmb x)}{{\rm d}a^2}=2\pi(a\mid\pmb x)>0,$
</center>

可知当决策函数 $a$ 为 $\theta$ 的后验分布的中位数时，后验风险达到最小，因此绝对值损失下 $\theta$ 的贝叶斯估计为
<center>
$\displaystyle a=\pi_{0.5}(\theta\mid\pmb x)=\hat{\theta}_B(\pmb x)$ $\bigg($ 即满足 $\displaystyle\int_{-\infty}^{a}\pi(\theta\mid\pmb x){\rm d}\theta=\dfrac{1}{2}\bigg).$
</center>

![](/img/in_post/Bayes/BayesLec4_2_6.png)

## 线性损失下的贝叶斯估计

在线性损失 
<center>
$L(\theta,a)=\left\{\begin{array}{ll}
k_0(\theta-a), & \theta\geq a,\\
k_1(a-\theta), & \theta<a.
\end{array}\right.$
</center>

下，$\theta$ 的贝叶斯估计为后验分布的 $\dfrac{k_0}{k_0+k_1}$ 分位数，即
<center>
$\hat{\theta}_B(\pmb x)=\pi_{k_0/(k_0+k_1)}(\theta\mid\pmb x)$ $\bigg($ 即满足 $\displaystyle\int_{-\infty}^{\hat{\theta}_B(\pmb x)}\pi(\theta\mid\pmb x){\rm d}\theta=\dfrac{k_0}{k_0+k_1}\bigg).$
</center>

**证明.** 设 $\pi(\theta\mid\pmb x)$ 为 $\theta$ 的后验密度，则决策函数 $a$ 的后验风险为
<center>
$\begin{array}{rl}
R(a\mid\pmb x)=&\!\!\!\!\displaystyle\mathbb E_{\theta\vert\pmb x}[L(\theta,a)]=\int_{-\infty}^{+\infty}L(\theta,a)\pi(\theta\mid\pmb x){\rm d}\theta\\
=&\!\!\!\!\displaystyle k_1\int_{-\infty}^a(a-\theta)\pi(\theta\mid\pmb x){\rm d}\theta+k_0\int_a^{+\infty}(\theta-a)\pi(\theta\mid\pmb x){\rm d}\theta\\
=&\!\!\!\!\displaystyle (k_0+k_1)\int_{-\infty}^a(a-\theta)\pi(\theta\mid\pmb x){\rm d}\theta+k_0\int_{-\infty}^{+\infty}(\theta-a)\pi(\theta\mid\pmb x){\rm d}\theta\\
=&\!\!\!\!\displaystyle (k_0+k_1)\int_{-\infty}^a(a-\theta)\pi(\theta\mid\pmb x){\rm d}\theta+k_0\big[\mathbb E(\theta\mid\pmb x)-a\big].
\end{array}$
</center>

由
<center>
$\displaystyle\dfrac{{\rm d}R(a\mid\pmb x)}{{\rm d}a}=(k_0+k_1)\int_{-\infty}^a\pi(\theta\mid\pmb x){\rm d}\theta-k_0=0,$

$\dfrac{{\rm d}^2R(a\mid\pmb x)}{{\rm d}a^2}=(k_0+k_1)\pi(a\mid\pmb x)>0,$
</center>

可知当决策函数 $a$ 为 $\theta$ 的后验分布的 $\dfrac{k_0}{k_0+k_1}$ 分位数时，后验风险达到最小，因此线性损失下 $\theta$ 的贝叶斯估计为
<center>
$\displaystyle a=\pi_{k_0/(k_0+k_1)}(\theta\mid\pmb x)=\hat{\theta}_B(\pmb x)$ $\bigg($ 即满足 $\displaystyle\int_{-\infty}^{a}\pi(\theta\mid\pmb x){\rm d}\theta=\dfrac{k_0}{k_0+k_1}\bigg).$
</center>

事实上，线性损失就是对绝对值损失的一般化。

![](/img/in_post/Bayes/BayesLec4_2_7.png)

## 0-1损失下的贝叶斯估计

在0-1损失函数（广义损失函数）
<center>
$L(\theta,a)=\left\{\begin{array}{ll}
	0, & \vert\theta-a\vert<\varepsilon,\\
	1, & \vert\theta-a\vert\geq\varepsilon
	\end{array}\right.$
</center>

（其中 $\varepsilon$ 是充分小的正数）下，$\theta$ 的贝叶斯估计为后验众数，即
<center>
$\hat{\theta}_B(\pmb x)=\underset{\theta\in\Theta}{\arg\max}~\pi(\theta\mid\pmb x).$
</center>

**证明.** 设 $\pi(\theta\mid\pmb x)$ 为 $\theta$ 的后验密度，则决策函数 $a$ 的后验风险为
<center>
$R(a\mid\pmb x)=\mathbb E_{\theta\vert\pmb x}[L(\theta,a)]=\mathbb P(\vert\theta-a\vert\geq\varepsilon)=1-\pi(\theta\mid\pmb x).$
</center>

因此后验风险最小即后验密度最大。

这一结果在假设检验问题中得到应用，将在下一节中介绍。

## 后记

本文内容参考自中国科学技术大学《贝叶斯分析》（2022Fall）课件。

如对本文内容有任何疑问，请联系 <watthu@mail.ustc.edu.cn>。