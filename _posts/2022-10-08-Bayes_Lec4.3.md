---
layout: post
title: "Bayes-Lec4.3 假设检验和区间估计"
subtitle: "Hypothesis and Interval Estimation"
author: "Watthu"
header-style: text
mathjax: true
tags:
  - 贝叶斯分析
---

在估计问题中一般有无穷多个行动可供选择，对这类问题使用贝叶斯统计决策方法是很容易解决的。例如，行动空间由 $r$ 个行动组成，即 $\mathscr{A}=\{a_1,\dots,a_r\}$。设在采取行动 $a_i$ 下的损失为 $L(\theta,a_i),i=1,\dots,r$，则贝叶斯决策就是选择使后验风险 $R(a_i\mid\pmb x)$ 达到最小的那个行动。

## 假设检验问题

设 $X\sim f(x\mid\theta)$，$\theta$的先验分布为 $\pi(\theta)$，$\pmb X=(X_1,\dots,X_n)$ 为从总体 $X$ 中抽取的i.i.d.样本，则 $\theta$ 的后验分布为
<center>
$\pi(\theta\mid\pmb x)=\dfrac{f(\pmb x\mid\theta)\pi(\theta)}{\int_{\Theta}f(\pmb x\mid\theta)\pi(\theta){\rm d}\theta}.$
</center>

待考察的假设检验问题为
<center>
$H_0:\theta\in\Theta_0\longleftrightarrow H_1:\theta\in\Theta_1,\quad\Theta_0\cup\Theta_1=\Theta.$
</center>

决策行动：$a_0$ 表示接受 $H_0$；$a_1$ 表示否定 $H_0$，接受 $H_1$。

---
**定理.** 设总体 $X\sim f(x\mid\theta),\theta\in\Theta=\Theta_0\cup\Theta_1$，$\theta$ 的先验分布为
<center>
$\pi(\theta)=\left\{\begin{array}{ll}
\pi_0g_0(\theta), & \theta\in\Theta_0,\\
\pi_1g_1(\theta), & \theta\in\Theta_1.
\end{array}\right.$
</center>

设 $\pmb X=(X_1,\dots,X_n)$ 为从总体 $X$ 中抽取的i.i.d.样本，损失函数
<center>
$L(\theta,a_i)=\left\{\begin{array}{ll}
0, & \theta\in\Theta_i,\\
k_i(\theta), & \theta\notin\Theta_i,
\end{array}\right.$
</center>

其中 $i=0,1$，且 $k_0(\theta),k_1(\theta)$ 为正函数。则贝叶斯决策函数为
<center>
$\delta(\pmb x)=\left\{\begin{array}{ll}
0, & \pmb x\notin W,\\ 1, & \pmb x\in W,
\end{array}\right.$
</center>

其中拒绝域 $W$ 为
<center>
$\displaystyle W=\left\{\pmb x:\pi_0\int_{\Theta_0}k_1(\theta)f(\pmb x\mid\theta)g_0(\theta){\rm d}\theta<\pi_1\int_{\Theta_1}k_0(\theta)f(\pmb x\mid\theta)g_1(\theta){\rm d}\theta\right\}.$
</center>

---

设 $\pi(\theta\mid\pmb x)$ 为 $\theta$ 的后验分布，则决策函数 $a_i(i=0,1)$ 的后验风险为
<center>
$\displaystyle R(a_i\mid\pmb x)=\mathbb{E}_{\theta\vert\pmb x}[L(\theta,a)]=\int_{\Theta_{1-a}}k_{a}(\theta)\pi(\theta\mid\pmb x){\rm d}\theta=\dfrac{\pi_{1-a}}{m(\pmb x)}\int_{\Theta_{1-a}}k_{a}(\theta)f(\pmb x\mid\theta)g_{1-a}(\theta){\rm d}\theta$
</center>

按后验风险最小原则，上述定理便得到证明。下面考虑几种特殊的情形：

### 0-1损失

若损失函数为0-1损失
<center>
$L(\theta,a_i)=\left\{\begin{array}{ll}
0, & \theta\in\Theta_i,\\
1, & \theta\notin\Theta_i,
\end{array}\right.\quad i=0,1,$
</center>

则后验风险为
<center>
$\displaystyle R(a_0\mid\pmb x)=\mathbb P(\theta\in\Theta_1\mid\pmb x),\quad R(a_1\mid\pmb x)=\mathbb P(\theta\in\Theta_0\mid\pmb x).$
</center>

因此按后验风险最小原则，对应的贝叶斯决策就是接受具有较大后验概率的假设，这与贝叶斯统计推断中的结论是一致的。

![](/img/in_post/Bayes/BayesLec4_3_1.png)

### 0-$k_i$ 损失

若损失函数为0-$k_i$ 损失
<center>
$L(\theta,a_i)=\left\{\begin{array}{ll}
0, & \theta\in\Theta_i,\\
k_i, & \theta\notin\Theta_i,
\end{array}\right.\quad i=0,1,$
</center>

则后验风险为
<center>
$\displaystyle R(a_0\mid\pmb x)=k_0\mathbb P(\theta\in\Theta_1\mid\pmb x),\quad R(a_1\mid\pmb x)=k_1\mathbb P(\theta\in\Theta_0\mid\pmb x).$
</center>

因此按后验风险最小原则，若 $\mathbb P(\theta\in\Theta_1\mid\pmb x)\geq\dfrac{k_1}{k_0+k_1}$，则否定 $H_0$，否则接受 $H_0$。

![](/img/in_post/Bayes/BayesLec4_3_2.png)

### 多决策问题

对于多决策问题，待考察的假设检验问题为
<center>
$H_i:\theta\in\Theta_i,\quad i=1,2,\dots,r.$
</center>

考虑损失函数为
<center>
$L(\theta,a_i)=\left\{\begin{array}{ll}
0, & \theta\in\Theta_i,\\
k_{ij}(\theta), & \theta\in\Theta_j(j\neq i),
\end{array}\right.\quad i=1,\dots,r,$
</center>

则后验风险为
<center>
$\displaystyle R(a_i\mid\pmb x)=\int_{\Theta}L(\theta,a_i)\pi(\theta\mid\pmb x){\rm d}\theta=\sum_{j=1}^r\int_{\Theta_j}k_{ij}(\theta)\pi(\theta\mid\pmb x){\rm d}\theta.$
</center>

因此按后验风险最小原则，取后验风险最小的那个决策为贝叶斯决策。

![](/img/in_post/Bayes/BayesLec4_3_3.png)

## 区间估计问题

设 $C(\pmb x)=(d_1(\pmb x),d_2(\pmb x))$ 为 $\theta$ 的一个区间估计，损失函数的一种取法为
<center>
$L(\theta,C(\pmb x))=m_1\big[d_2(\pmb x)-d_1(\pmb x)\big]+m_2\big[1-I\{\theta\in C(\pmb x)\}\big].$
</center>

按后验风险的原则，应使区间估计的后验风险
<center>
$R(C(\pmb x)\mid\pmb x)=m_1\big[d_2(\pmb x)-d_1(\pmb x)\big]+m_2\mathbb P_{\theta\vert\pmb x}(\theta\notin C(\pmb x))$
</center>

越小越好，但是要找出最优解并非易事，优化问题能够得以解决的不多。

## 后记

本文内容参考自中国科学技术大学《贝叶斯分析》（2022Fall）课件。

如对本文内容有任何疑问，请联系 <watthu@mail.ustc.edu.cn>。